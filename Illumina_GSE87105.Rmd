---
title: "test"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# llll

```{r echo=FALSE}
library(illuminaHumanv4.db)
library(ggpubr)
library(GEOquery)
library(limma)
library(gplots)
library(dplyr)
```
## Getting the data

For this part, the first thing is to analyze the experiment and the chipset used so I can map the names and the classes that the samples belong to. 

```{r}
experiment <- "GSE87105"
chip <- "GPL10558"
# coding subtypes, 0 = YOUNG, 1 = MIDDLE AGE, 2 = OLD
s_classes <- "0000011112222222"
class_names <- c("YOUNG","MIDDLE","OLD")
```
## Importing the Data

```{r}

my_id <- experiment
gse <- getGEO(my_id)#, GSEMatrix =TRUE)
```
```{r}
if (length(gse) > 1) idx <- grep(chip, attr(gse, "names")) else idx <- 1
gset <- gse[[idx]]
```

```{r}
pData(gset)
fData(gset)
fvarLabels(gset)
```
```{r}
fvarLabels(gset) <- make.names(fvarLabels(gset))
features <- fData(gset)
features
```

```{r}

gsms <- s_classes
sml <- strsplit(gsms, split="")[[1]]
```

## Check normalisation and scales used

Log2 scale transformation required

Check for normalisation by looking at boxplot of expression levels for each sample


```{r}
ex <- exprs(gset) # expression data, what form is this?
qx <- as.numeric(quantile(ex, c(0., 0.25, 0.5, 0.75, 0.99, 1.0), na.rm=T))
LogC <- (qx[5] > 100) ||
  (qx[6]-qx[1] > 50 && qx[2] > 0)
if (LogC) { ex[which(ex <= 0)] <- NaN
exprs(gset) <- log2(ex) } # i think this code is trying to determine whether the data is in log2 format yet


gs <- factor(sml)
groups <- make.names(class_names)
levels(gs) <- groups
gset$group <- gs
ord <- order(gs)  # order samples by group

palette <- palette(c("#1B9E77", "#7570B3", "#E7298A", "#E6AB02", "#D95F02",
          "#66A61E", "#A6761D", "#B32424", "#B324B3", "#666666"))
par(mar=c(7,4,2,1))
title <- paste (experiment, "/", annotation(gset), sep ="")
boxplot(log2(ex[,ord]), boxwex=0.6, notch=T, main=title, outline=FALSE, las=2, col=gs[ord])
legend("topleft", groups, fill=palette(), bty="n")
```


```{r}
boxplot(log2(ex),range=0,ylab="log2 intensity")
```


## Probe filtering

```{r}
# expression value distribution
par(mar=c(4,4,2,1))
title <- paste ("Normalized Expression Density", sep ="")
plotDensities(ex[,ord], group=gs, main=title, legend ="topright")
```

```{r}
# Probe filtering
medians <- rowMedians(ex)
man_threshold <- 4 

hist(medians, 150, col = "cornsilk1", freq = FALSE, 
main = "Histogram of the median intensities", 
border = "antiquewhite4",
xlab = "Median intensities")
```

```{r}
meta <- pData(gset)
meta$group
```

```{r}
no_of_samples <- table(meta$group)
sample_cutoff <- min(no_of_samples)

idx_man_threshold <- apply(Biobase::exprs(gset), 1, function(x){ sum(x > man_threshold) >= sample_cutoff})

table(idx_man_threshold)
```

```{r}
probes <- rownames(gset)

library(illuminaHumanv4.db)
annotation <- AnnotationDbi::select(illuminaHumanv4.db,
                                    keys = probes,
                                    columns = c("SYMBOL", "GENENAME"),
                                    keytype = "PROBEID")
```
```{r}
annotation <- subset(annotation, !is.na(SYMBOL))

## resolve multi maps. 

ann_grouped <- group_by(annotation, PROBEID)
ann_sum <- dplyr::summarize(ann_grouped, no_of_matches = n_distinct(SYMBOL))

ann_flt <- filter(ann_sum, no_of_matches > 1)

remove_id <- (featureNames(gset) %in% ann_flt$PROBEID)

table(remove_id)
```

```{r}
final_annotation <- subset(annotation, !remove_id)
final_Obj <- subset(gset, !remove_id)

fData(final_Obj)$PROBEID <- rownames(fData(final_Obj))

fData(final_Obj) <- left_join(fData(final_Obj), annotation)
rownames(fData(final_Obj)) <- fData(final_Obj)$PROBEID

```

```{r}
batches <- as.factor(gset$group)

col.status <- c("blue","red","dark green")[batches]
plotMDS(gset, col = col.status, pch = 16)
```


## Design matrix

```{r}
design <- model.matrix(~group + 0, gset)
colnames(design) <- levels(gs)
fit <- lmFit(gset, design)

# Set up contrasts of interest
cts <- paste(groups, c(tail(groups, -1), head(groups, 1)), sep="-")
cont.matrix <- makeContrasts(contrasts=cts, levels=design)
fit2 <- contrasts.fit(fit, cont.matrix)
fit2 <- eBayes(fit2, 0.01)
# print contrasts order
comparisons <-colnames(fit2[["coefficients"]])
```
Now there is this function that will take all the analysis over each pair.

```{r get_DE_analysis} 

DE_analysis <- function(comparison) {
  coefficient_v =  which(comparisons ==comparison)
  #Create the top table for the comparison (coef) we want
  top <- topTable(fit2, coef=3, adjust.method = "fdr", sort.by="B", number = Inf)
  nrow(top)
  
  #Top Table of significant genes only
  up_reg_epi <- subset(top, adj.P.Val < 0.1)
  nrow(up_reg_epi)
  
  #Create an excel-readable table with the specified columns for sig gene only
  tT <- subset(up_reg_epi, select=c("Symbol","logFC","adj.P.Val","P.Value","t"))
  filename = paste0("DEG_list_",experiment,"_",comparison, ".csv")
  write.table(tT, filename, row.names=F, sep="\t")
  
  #Sanity check - hist of all P vals
  hist(top$adj.P.Val, col = "grey", border = "white", xlab = "P-adj",
       ylab = "Number of genes", main = "P-adj value distribution")
}
lapply(comparisons, DE_analysis)
```

```{r}
# Hist of sig DEG P values
hist(up_reg_epi$adj.P.Val, col = "grey", border = "white", xlab = "P-adj",
     ylab = "Number of genes", main = "P-adj value distribution")
```

```{r}
#Extract the expression values for the DEGs
e <- exprs(gset)
sig_exprs <- e[rownames(e) %in% as.character(tT$ID),]
```

```{r}
#library(DT)
#::datatable(up_reg_epi, rownames = FALSE, options=list(scrollX=T))
```


```{r}
# summarize test results as "up", "down" or "not expressed"
dT <- decideTests(fit2, adjust.method="fdr", p.value=0.1)
vennDiagram(dT, circle.col=palette())
```

```{r}
# create Q-Q plot for t-statistic
t.good <- which(!is.na(fit2$F)) # filter out bad probes
qqt(fit2$t[t.good], fit2$df.total[t.good], main="Moderated t statistic")
```

```{r}
# volcano plot (log P-value vs log fold change)
colnames(fit2) # list contrast names
ct <- 1
# choose contrast of interest
volcanoplot(fit2, coef=ct, main=colnames(fit2)[ct], pch=20,
            highlight=length(which(dT[,ct]!=0)), names=rep('+', nrow(fit2)))
```

```{r}
ct <- 2
# choose contrast of interest
volcanoplot(fit2, coef=ct, main=colnames(fit2)[ct], pch=20,
            highlight=length(which(dT[,ct]!=0)), names=rep('+', nrow(fit2)))
```

```{r}
ct <- 3
# choose contrast of interest
volcanoplot(fit2, coef=ct, main=colnames(fit2)[ct], pch=20,
            highlight=length(which(dT[,ct]!=0)), names=rep('+', nrow(fit2)))
```

## MD plot (log fold change vs mean log expression) highlight statistically significant (p-adj < 0.05) probes

```{r}
ct <- 1
plotMD(fit2, column=ct, status=dT[,ct], legend=F, pch=20, cex=1)
abline(h=0)
```

```{r}
ct <- 2
plotMD(fit2, column=ct, status=dT[,ct], legend=F, pch=20, cex=1)
abline(h=0)
```

```{r}
ct <- 3
plotMD(fit2, column=ct, status=dT[,ct], legend=F, pch=20, cex=1)
abline(h=0)
```

## Heat Map

```{r}
library(pheatmap)
annotation_for_heatmap <- 
  data.frame(Subtype = gset$group)

dists <- as.matrix(dist(t(exprs(gset)), method = "manhattan"))
rownames(dists) <- row.names(annotation_for_heatmap)
hmcol <- rev(colorRampPalette(RColorBrewer::brewer.pal(9, "YlOrRd"))(255))
colnames(dists) <- NULL
diag(dists) <- NA

ann_colors <- list(
  Subtype = c(YOUNG = "purple", MIDDLE = "forestgreen", OLD = "cyan3"))

pheatmap(dists, col = (hmcol), 
         annotation_row = annotation_for_heatmap,
         annotation_colors = ann_colors,
         legend = TRUE, 
         show_rownames = FALSE,
         treeheight_row = 0,
         legend_breaks = c(min(dists, na.rm = TRUE), 
                         max(dists, na.rm = TRUE)), 
         legend_labels = (c("small distance", "large distance")),
         main = "Clustering heatmap normalised samples")
```

## Further things to consider

 -  Carried out in 2 batches - possible batch effects? PCA colour by batch
 -  How to deal with biolocgial replicates - in initial study they were averaged...
 -  GSEA, ORA
 -  Can the results from the initial study be replicated? If so/if not, something to talk about in the paper anyway!
 -  Data integration strategy
 -  The model itself
